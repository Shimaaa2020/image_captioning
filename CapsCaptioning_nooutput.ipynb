{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from PIL import Image\n",
    "from cache import cache\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import layers, models, optimizers, callbacks\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU, Embedding, Conv2D, Layer, concatenate\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "sess = tf.Session(config=config)\n",
    "tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=\"0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.device(\"/device:GPU:0\")\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco.download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, filenames_train, captions_train =coco.load_records(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asanyarray(captions_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, filenames_test, captions_test = coco.load_records(train=False)\n",
    "_, filenames_val, captions_val = coco.load_records(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_train = len(filenames_train)\n",
    "print(\"number of train images : \",num_images_train)\n",
    "num_caption_train = len(captions_train)\n",
    "print(\"number of train captions : \",num_caption_train)\n",
    "num_images_val = len(filenames_val)\n",
    "print(\"number of validation images : \",num_images_val)\n",
    "num_caption_val = len(captions_val)\n",
    "print(\"number of validation captions : \",num_caption_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_test=filenames_val\n",
    "captions_test=captions_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_val = len(filenames_val)\n",
    "num_images_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size=None):\n",
    "    \n",
    "\n",
    "  \n",
    "    img = Image.open(path)\n",
    "\n",
    "    if not size is None:\n",
    "        img = img.resize(size=size, resample=Image.LANCZOS)\n",
    "\n",
    "\n",
    "    img = np.array(img)\n",
    "\n",
    "\n",
    "    img = img / 255.0\n",
    "\n",
    "   \n",
    "    if (len(img.shape) == 2):\n",
    "        img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(idx, train):\n",
    "   \n",
    "\n",
    "    if train:\n",
    "        \n",
    "        dir = coco.train_dir\n",
    "        filename = filenames_train[idx]\n",
    "        captions = captions_train[idx]\n",
    "    else:\n",
    "       \n",
    "        dir = coco.val_dir\n",
    "        filename = filenames_val[idx]\n",
    "        captions = captions_val[idx]\n",
    "\n",
    " \n",
    "    path = os.path.join(dir, filename)\n",
    "\n",
    "\n",
    "    for caption in captions:\n",
    "        print(caption)\n",
    "    \n",
    " \n",
    "    img = load_image(path)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_image(idx=100, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_model = InceptionV3()\n",
    "print (image_model.summary())\n",
    "transfer_layer=image_model.get_layer('avg_pool')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "import argparse\n",
    "# from keras import  optimizers, callbacks\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from utils3 import combine_images,plot_log\n",
    "from capsule_layers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "def CapsNet(input_shape, n_class, routings):\n",
    "\n",
    "    x = Input(shape=input_shape)\n",
    "\n",
    "    \n",
    "    conv1 = Conv2D(filters=96, kernel_size=13, strides=4, padding='valid', activation='relu', name='conv1')(x)\n",
    "    conv2 = Conv2D(filters=96, kernel_size=5, strides=2, padding='valid', activation='relu', name='conv2')(conv1)\n",
    "    conv3 = Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv3')(conv2)\n",
    "\n",
    "\n",
    "  \n",
    "    primary_caps = PrimaryCap(conv3, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "    \n",
    "    category_caps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,name='category_caps')(primary_caps)\n",
    "\n",
    "   \n",
    "    out_caps = Length(name='capsnet')(category_caps)\n",
    "\n",
    "   \n",
    "    y = Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([category_caps, y])  training\n",
    "    masked = Mask()(category_caps) \n",
    "\n",
    "    \n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(Dense(512, activation='relu', input_dim=16*n_class))\n",
    "    decoder.add(Dense(1024, activation='relu'))\n",
    "\n",
    "    \n",
    "  \n",
    "    train_model = Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "\n",
    "    noise = Input(shape=(n_class, 16))\n",
    "    noised_category_caps = layers.Add()([category_caps, noise])\n",
    "    masked_noised_y = Mask()([noised_category_caps, y])\n",
    "    manipulate_model =Model([x, y, noise], decoder(masked_noised_y))\n",
    "\n",
    "    return train_model, eval_model, manipulate_model\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    \n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))\n",
    "\n",
    "\n",
    "def train(model, data, args):\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "\n",
    "  \n",
    "    log = callbacks.CSVLogger(args['save_dir'] + '/log.csv')\n",
    "    tb = callbacks.TensorBoard(log_dir=args['save_dir'] + '/tensorboard-logs',\n",
    "                               batch_size=args['batch_size'], histogram_freq=int(args['debug']))\n",
    "    checkpoint = callbacks.ModelCheckpoint(args['save_dir'] + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
    "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
    "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args['lr'] * (args['lr_decay'] ** epoch))\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "   \n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args['lr']),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., args['lam_recon']],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    \n",
    "\n",
    "    model.fit(\n",
    "        [x_train, y_train],\n",
    "        [y_train, x_train],\n",
    "        batch_size=args['batch_size'],\n",
    "        epochs=args['epochs'],\n",
    "        validation_data=[[x_test, y_test], [y_test, x_test]],\n",
    "        callbacks=[log, tb, checkpoint, lr_decay, early_stop]\n",
    "    )\n",
    "\n",
    "def test(model, data, args):\n",
    "    x_test, y_test = data\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
    "    print('-' * 30 + 'Begin: test' + '-' * 30)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0])\n",
    "\n",
    "    img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
    "    print()\n",
    "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
    "    print('-' * 30 + 'End: test' + '-' * 30)\n",
    "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def manipulate_latent(model, data, args):\n",
    "    print('-' * 30 + 'Begin: manipulate' + '-' * 30)\n",
    "    x_test, y_test = data\n",
    "    index = np.argmax(y_test, 1) == args.digit\n",
    "    number = np.random.randint(low=0, high=sum(index) - 1)\n",
    "    x, y = x_test[index][number], y_test[index][number]\n",
    "    x, y = np.expand_dims(x, 0), np.expand_dims(y, 0)\n",
    "    noise = np.zeros([1, 80, 16])\n",
    "    x_recons = []\n",
    "    for dim in range(16):\n",
    "        for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n",
    "            tmp = np.copy(noise)\n",
    "            tmp[:, :, dim] = r\n",
    "            x_recon = model.predict([x, y, tmp])\n",
    "            x_recons.append(x_recon)\n",
    "\n",
    "    x_recons = np.concatenate(x_recons)\n",
    "\n",
    "    img = combine_images(x_recons, height=16)\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/manipulate-%d.png' % args.digit)\n",
    "    print('manipulated result saved to %s/manipulate-%d.png' % (args.save_dir, args.digit))\n",
    "    print('-' * 30 + 'End: manipulate' + '-' * 30)\n",
    "\n",
    "\n",
    "\n",
    "def load_coco(dataset_file, map_file):\n",
    "    \"\"\"\n",
    "    Load preprocessed MSCOCO 2017 dataset\n",
    "    \"\"\"\n",
    "    print('\\nLoading dataset...')\n",
    "    \n",
    " \n",
    "    h5f = h5py.File(dataset_file, 'r')\n",
    "    x = h5f['x'][:]\n",
    "    y = h5f['y'][:]\n",
    "    h5f.close()\n",
    "\n",
    "    split = int(x.shape[0] * 0.8)  # 80% of data is assigned to the training set\n",
    "    x_train, y_train = x[:split], y[:split]\n",
    "    x_test, y_test = x[split:], y[split:]\n",
    "\n",
    "    with open(map_file, 'rb') as mapping:\n",
    "        category_id_map = pickle.load(mapping)\n",
    "    id_category = category_id_map['id_category']\n",
    "    print('Done.')\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test), id_category\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Capsule Network on MSCOCO 2017.\")\n",
    "    parser.add_argument('--epochs', default=1, type=int)\n",
    "    parser.add_argument('--batch_size', default=100, type=int)\n",
    "    parser.add_argument('--lr', default=0.001, type=float, help=\"Initial learning rate\")\n",
    "    parser.add_argument('--lr_decay', default=1, type=float,\n",
    "                        help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
    "    parser.add_argument('--lam_recon', default=0.392, type=float, help=\"The coefficient for the loss of decoder\")\n",
    "    parser.add_argument('-r', '--routings', default=3, type=int,\n",
    "                        help=\"Number of iterations used in routing algorithm. should > 0\")  # num_routing should > 0\n",
    "    parser.add_argument('--debug', action='store_true', help=\"Save weights by TensorBoard\")\n",
    "    parser.add_argument('--save_dir', default='./result')\n",
    "    parser.add_argument(\n",
    "        '--dataset_file', default=os.path.join(os.path.dirname(os.path.abspath('__file__')), 'dataset/capsnet_train_data.h5'),\n",
    "        help='File having the preprocessed dataset')\n",
    "    parser.add_argument('-t', '--testing', action='store_true',\n",
    "                        help='Test the trained model on testing dataset')\n",
    "    parser.add_argument('--digit', default=5, type=int,\n",
    "                        help=\"Digit to manipulate\")\n",
    "    parser.add_argument('-w', '--weights', default=None,\n",
    "                        help=\"The path of the saved weights. Should be specified when testing\")\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--map_file', default=os.path.join(os.path.dirname(os.path.realpath('__file__')), 'dataset/coco_raw.pickle'),\n",
    "        help='File having the id to category map'\n",
    "    )\n",
    "    args = parser.parse_known_args()[0]\n",
    "    print(args)\n",
    "\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir)\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test), id_category = load_coco(args.dataset_file, args.map_file)\n",
    "\n",
    "\n",
    "    model, eval_model, manipulate_model = CapsNet(\n",
    "        input_shape=(299, 299, 3),\n",
    "        n_class=y_train.shape[1],\n",
    "        routings=args.routings\n",
    "    )\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_layer = image_model.get_layer('predictions')\n",
    "label_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_model.input)\n",
    "print(image_model.input)\n",
    "print(eval_model.output[1])\n",
    "print(transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat([eval_model.output[1],transfer_layer.output],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_model=models.Model(inputs=eval_model.input,outputs=eval_model.output[1])\n",
    "capsule_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_model_transfer = models.Model(inputs=image_model.input, outputs=image_model.get_layer('avg_pool').output)\n",
    "# image_model_transfer= image_model\n",
    "image_model_transfer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = K.int_shape(image_model.input)[1:3]\n",
    "img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filenames_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transfer_values_size=3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(count, max_count):\n",
    "\n",
    "    pct_complete = count / max_count\n",
    "\n",
    "\n",
    "    msg = \"\\r- Progress: {0:.1%}\".format(pct_complete)\n",
    "\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(data_dir, filenames, batch_size=32):\n",
    "    \"\"\"\n",
    "    Process all the given files in the given data_dir using the\n",
    "    pre-trained image-model and return their transfer-values.\n",
    "    \n",
    "    Note that we process the images in batches to save\n",
    "    memory and improve efficiency on the GPU.\n",
    "    \"\"\"\n",
    "\n",
    "    num_images = len(filenames)\n",
    "\n",
    "    shape = (batch_size,) + img_size + (3,)\n",
    "    image_batch = np.zeros(shape=shape, dtype=np.float16)\n",
    "\n",
    "    shape = (num_images, transfer_values_size)\n",
    "    transfer_values = np.zeros(shape=shape, dtype=np.float16)\n",
    "\n",
    "\n",
    "    start_index = 0\n",
    "\n",
    "\n",
    "    while start_index < num_images:\n",
    "\n",
    "        print_progress(count=start_index, max_count=num_images)\n",
    "\n",
    "   \n",
    "        end_index = start_index + batch_size\n",
    "\n",
    "     \n",
    "        if end_index > num_images:\n",
    "            end_index = num_images\n",
    "\n",
    "\n",
    "        current_batch_size = end_index - start_index\n",
    "\n",
    "        for i, filename in enumerate(filenames[start_index:end_index]):\n",
    "           \n",
    "            path = os.path.join(data_dir, filename)\n",
    "\n",
    "\n",
    "            img = load_image(path, size=img_size)\n",
    "\n",
    "            \n",
    "            image_batch[i] = img\n",
    "\n",
    "        \n",
    "        transfer_values_batch = \\\n",
    "            np.concatenate([image_model_transfer.predict(image_batch[0:current_batch_size]),capsule_model.predict(image_batch[0:current_batch_size])],1)\n",
    "            \n",
    "        transfer_values[start_index:end_index] = \\\n",
    "            transfer_values_batch[0:current_batch_size]\n",
    "\n",
    "        start_index = end_index\n",
    "\n",
    "\n",
    "    print()\n",
    "\n",
    "    return transfer_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_label(data_dir, filenames, batch_size=32):\n",
    "\n",
    "    num_images = len(filenames)\n",
    "     \n",
    "\n",
    "    shape = (batch_size,) + img_size + (3,)\n",
    "    shape2 = (batch_size,) + (1000,)\n",
    "    image_batch = np.zeros(shape=shape, dtype=np.float16)\n",
    "    shape2 = (num_images,1000)\n",
    "    label_values = np.zeros(shape=shape2, dtype=np.float16)\n",
    "\n",
    "    start_index = 0\n",
    "\n",
    "    while start_index < num_images:\n",
    "\n",
    "        print_progress(count=start_index, max_count=num_images)\n",
    "\n",
    "        end_index = start_index + batch_size\n",
    "\n",
    "        if end_index > num_images:\n",
    "            end_index = num_images\n",
    "\n",
    "        current_batch_size = end_index - start_index\n",
    "\n",
    "        for i, filename in enumerate(filenames[start_index:end_index]):\n",
    "           \n",
    "            path = os.path.join(data_dir, filename)\n",
    "\n",
    "\n",
    "            img = load_image(path, size=img_size)\n",
    "\n",
    "            image_batch[i] = img\n",
    "\n",
    "\n",
    "        label_value_batch = image_model.predict(image_batch[0:current_batch_size])\n",
    "\n",
    "        label_values[start_index:end_index] =label_value_batch[0:current_batch_size]\n",
    "\n",
    "        start_index = end_index\n",
    "\n",
    "\n",
    "    print()\n",
    "\n",
    "    return label_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_train():\n",
    "    print(\"Processing {0} images in training-set ...\".format(len(filenames_train)))\n",
    "    cache_path1 = os.path.join(coco.data_dir,\n",
    "                              \"capsule_inception_train.pkl\")\n",
    "    cache_path2 = os.path.join(coco.data_dir, \"label_inception_train.pkl\")\n",
    "\n",
    "    transfer_values = cache(cache_path=cache_path1,\n",
    "                            fn=process_images,\n",
    "                            data_dir=coco.train_dir,\n",
    "                            filenames=filenames_train)\n",
    "\n",
    "    label_values = cache(cache_path=cache_path2,\n",
    "                            fn=process_images_label,\n",
    "                            data_dir=coco.train_dir,\n",
    "                            filenames=filenames_train)\n",
    "\n",
    "    return transfer_values,label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[transfer_values,label_values]=process_images_train()\n",
    "print(np.asanyarray(transfer_values).shape)\n",
    "print(np.asanyarray(label_values).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_val():\n",
    "    print(\"Processing {0} images in validation-set ...\".format(len(filenames_val)))\n",
    "\n",
    "    \n",
    "    cache_path1 = os.path.join(coco.data_dir, \"capsule_inception_val.pkl\")\n",
    "    cache_path2 = os.path.join(coco.data_dir, \"label_inception_val.pkl\")\n",
    "\n",
    "   \n",
    "    transfer_values = cache(cache_path=cache_path1,\n",
    "                            fn=process_images,\n",
    "                            data_dir=coco.val_dir,\n",
    "                            filenames=filenames_val)\n",
    "    label_values = cache(cache_path=cache_path2,\n",
    "                            fn=process_images_label,\n",
    "                            data_dir=coco.val_dir,\n",
    "                            filenames=filenames_val)\n",
    "    \n",
    "\n",
    "    return transfer_values,label_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[transfer_values,label_values]=process_images_val()\n",
    "print(np.asanyarray(transfer_values).shape)\n",
    "print(np.asanyarray(label_values).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "[capsule_inception_train,label_inception_train] = process_images_train()\n",
    "print(\"dtype:\", capsule_inception_train.dtype)\n",
    "print(\"shape:\", capsule_inception_train.shape)\n",
    "print(\"dtype:\", label_inception_train.dtype)\n",
    "print(\"shape:\", label_inception_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[capsule_inception_val,label_inception_val] = process_images_val()\n",
    "print(\"dtype:\", capsule_inception_val.dtype)\n",
    "print(\"shape:\", capsule_inception_val.shape)\n",
    "print(\"dtype:\", label_inception_val.dtype)\n",
    "print(\"shape:\", label_inception_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_test=capsule_inception_val\n",
    "label_test=label_inception_val\n",
    "temp1=capsule_inception_train\n",
    "temp2=label_inception_train\n",
    "temp3=filenames_train\n",
    "temp4=captions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train_train=captions_train\n",
    "print(capsule_inception_train.shape)\n",
    "print(label_inception_train.shape)\n",
    "print(capsule_inception_val.shape)\n",
    "print(label_inception_val.shape)\n",
    "print(np.asanyarray(captions_train_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asanyarray(filenames_val).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_applications.inception_v3 import decode_predictions \n",
    "yhat=decode_predictions(label_inception_train, top=3, utils=tf.keras.utils)\n",
    "yhat2=decode_predictions(label_inception_val, top=5, utils=tf.keras.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((np.asanyarray(yhat))[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_labels=(np.asanyarray(yhat)[:,:,1])\n",
    "print(extra_labels[0:5,:])\n",
    "\n",
    "extra_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "captions_train2=captions_train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train2_list=[]\n",
    "captions_train2_list\n",
    "capsule_inception_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "wiki_wiki = wikipediaapi.Wikipedia(language='en', extract_format=wikipediaapi.ExtractFormat.WIKI)\n",
    "path='/home/javanmardis/shima/CapsNet-COCO-master/Caption_file.npy'\n",
    "captions_train2 = np.load(\"Caption_file.npy\",allow_pickle=\"True\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "for cc in range (len(captions_train2)):\n",
    "    captions_train2[cc] = [''.join(c for c in s if c not in string.punctuation) for s in captions_train2[cc]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train2[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_start = 'ssss '\n",
    "mark_end = ' eeee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train=captions_train2\n",
    "len(captions_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_captions(captions_listlist):\n",
    "    captions_marked = [[mark_start + caption + mark_end\n",
    "                        for caption in captions_list]\n",
    "                        for captions_list in captions_listlist]\n",
    "    \n",
    "    return captions_marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train_marked = mark_captions(captions_train)\n",
    "captions_train_marked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(captions_listlist):\n",
    "    captions_list = [caption\n",
    "                     for captions_list in captions_listlist\n",
    "                     for caption in captions_list]\n",
    "    \n",
    "    return captions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train_flat = flatten(captions_train_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerWrap(Tokenizer):\n",
    "   \n",
    "    def __init__(self, texts, num_words=None):\n",
    "       \n",
    "\n",
    "        Tokenizer.__init__(self, num_words=num_words)\n",
    "\n",
    "     \n",
    "        self.fit_on_texts(texts)\n",
    "\n",
    "        \n",
    "        self.index_to_word = dict(zip(self.word_index.values(),\n",
    "                                      self.word_index.keys()))\n",
    "\n",
    "    def token_to_word(self, token):\n",
    "        \n",
    "\n",
    "        word = \" \" if token == 0 else self.index_to_word[token]\n",
    "        return word \n",
    "\n",
    "    def tokens_to_string(self, tokens):\n",
    "        \n",
    "\n",
    "        \n",
    "        words = [self.index_to_word[token]\n",
    "                 for token in tokens\n",
    "                 if token != 0]\n",
    "        \n",
    "\n",
    "        text = \" \".join(words)\n",
    "\n",
    "        return text\n",
    "    \n",
    "    def captions_to_tokens(self, captions_listlist):\n",
    "\n",
    "        \n",
    "        \n",
    "        tokens = [self.texts_to_sequences(captions_list)\n",
    "                  for captions_list in captions_listlist]\n",
    "        \n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokenizer = TokenizerWrap(texts=captions_train_flat,\n",
    "                          num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index[\"one\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_start = tokenizer.word_index[mark_start.strip()]\n",
    "token_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_end = tokenizer.word_index[mark_end.strip()]\n",
    "token_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tokens_train = tokenizer.captions_to_tokens(captions_train_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "captions_train_marked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_caption_tokens(idx):\n",
    "    \n",
    "    \n",
    "    \n",
    "    result = []\n",
    "\n",
    "    \n",
    "    for i in idx:\n",
    "        \n",
    "        j = np.random.choice(len(tokens_train[i]))\n",
    "\n",
    "       \n",
    "        tokens = tokens_train[i][j]\n",
    "\n",
    "\n",
    "        result.append(tokens)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(num_images_train)\n",
    "\n",
    "print(num_caption_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asanyarray(filenames_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsule_inception_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \n",
    "    Note that it selects the data completely randomly for each\n",
    "    batch, corresponding to sampling of the training-set with\n",
    "    replacement. This means it is possible to sample the same\n",
    "    data multiple times within a single epoch - and it is also\n",
    "    possible that some data is not sampled at all within an epoch.\n",
    "    However, all the data should be unique within a single batch.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    while True:\n",
    "       \n",
    "        idx = np.random.randint(num_images_train,\n",
    "                                size=batch_size)\n",
    "        \n",
    "        \n",
    "        transfer_values = capsule_inception_train[idx]\n",
    "\n",
    "        \n",
    "        tokens = get_random_caption_tokens(idx)\n",
    "\n",
    "        \n",
    "        num_tokens = [len(t) for t in tokens]\n",
    "        \n",
    "        \n",
    "        max_tokens = np.max(num_tokens)\n",
    "        \n",
    "        \n",
    "        tokens_padded = pad_sequences(tokens,\n",
    "                                      maxlen=max_tokens,\n",
    "                                      padding='post',\n",
    "                                      truncating='post')\n",
    "        \n",
    "        \n",
    "        decoder_input_data = tokens_padded[:, 0:-1]\n",
    "        decoder_output_data = tokens_padded[:, 1:]\n",
    "\n",
    "        \n",
    "        x_data = \\\n",
    "        {\n",
    "            'decoder_input': decoder_input_data,\n",
    "            'transfer_values_input': transfer_values\n",
    "        }\n",
    "\n",
    "       \n",
    "        y_data = \\\n",
    "        {\n",
    "            'decoder_output': decoder_output_data\n",
    "        }\n",
    "        \n",
    "        yield (x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = batch_generator(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(generator)\n",
    "batch_x = batch[0]\n",
    "batch_y = batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(batch_x['transfer_values_input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(batch_x['decoder_input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y['decoder_output'][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(batch_x['decoder_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(batch_y['decoder_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor((batch_x['decoder_input']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_captions_train = [len(captions) for captions in captions_train]\n",
    "len(captions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_captions_train = np.sum(num_captions_train)\n",
    "total_num_captions_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(total_num_captions_train / batch_size)\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_input = Input(shape=(transfer_values_size,),\n",
    "                              name='transfer_values_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_transfer_map = Dense(state_size,\n",
    "                             activation='tanh',\n",
    "                             name='decoder_transfer_map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None, ), name='decoder_input')\n",
    "decoder_input.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_embedding = Embedding(input_dim=num_words,\n",
    "                              output_dim=embedding_size,\n",
    "                              name='decoder_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_gru1 = GRU(state_size, name='decoder_gru1',\n",
    "                   return_sequences=True)\n",
    "decoder_gru2 = GRU(state_size, name='decoder_gru2',\n",
    "                   return_sequences=True)\n",
    "decoder_gru3 = GRU(state_size, name='decoder_gru3',\n",
    "                   return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_words,\n",
    "                      activation='linear',\n",
    "                      name='decoder_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_decoder(transfer_values):\n",
    "\n",
    "    initial_state = decoder_transfer_map(transfer_values)\n",
    "\n",
    "    \n",
    "    net = decoder_input\n",
    "\n",
    "\n",
    "    net = decoder_embedding(net)\n",
    "    \n",
    "\n",
    "    net = decoder_gru1(net, initial_state=initial_state)\n",
    "    net = decoder_gru2(net, initial_state=initial_state)\n",
    "    net = decoder_gru3(net, initial_state=initial_state)\n",
    "\n",
    "    \n",
    "    decoder_output = decoder_dense(net)\n",
    "    \n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_values_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = connect_decoder(transfer_values=transfer_values_input)\n",
    "\n",
    "decoder_model = Model(inputs=[transfer_values_input, decoder_input],\n",
    "                      outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_y['decoder_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x['decoder_input'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cross_entropy(y_true, y_pred):\n",
    "    \n",
    "\n",
    "    \n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,\n",
    "                                                          logits=y_pred)\n",
    "\n",
    "    \n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder_target = tf.placeholder(dtype='int32', shape=(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.compile(optimizer=optimizer,\n",
    "                      loss=sparse_cross_entropy,\n",
    "\n",
    "                      target_tensors=[decoder_target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = '22_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_tensorboard = TensorBoard(log_dir='./22_logs/',\n",
    "                                   histogram_freq=1,\n",
    "                                   write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback_checkpoint, callback_tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    decoder_model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history=decoder_model.fit_generator(generator=generator,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=1,\n",
    "                            callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(image_path, max_tokens=30):\n",
    "    \n",
    "    image = load_image(image_path, size=img_size)\n",
    "    \n",
    "   \n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "\n",
    "    \n",
    "    transfer_values1 = image_model_transfer.predict(image_batch)\n",
    "    transfer_values2 = capsule_model.predict(image_batch)\n",
    "    transfer_values=np.concatenate([transfer_values1,transfer_values2],1)\n",
    "\n",
    "   \n",
    "    shape = (1, max_tokens)\n",
    "    decoder_input_data = np.zeros(shape=shape, dtype=np.int)\n",
    "\n",
    "   \n",
    "    token_int = token_start\n",
    "\n",
    "    \n",
    "    output_text = ''\n",
    "\n",
    "    \n",
    "    count_tokens = 0\n",
    "\n",
    "    \n",
    "    while token_int != token_end and count_tokens < max_tokens:\n",
    "        \n",
    "        decoder_input_data[0, count_tokens] = token_int\n",
    "\n",
    "        \n",
    "        x_data = \\\n",
    "        {\n",
    "            'transfer_values_input': transfer_values,\n",
    "            'decoder_input': decoder_input_data\n",
    "        }\n",
    "\n",
    "       \n",
    "       \n",
    "        decoder_output = decoder_model.predict(x_data)\n",
    "\n",
    "       \n",
    "        token_onehot = decoder_output[0, count_tokens, :]\n",
    "\n",
    "        \n",
    "        token_int = np.argmax(token_onehot)\n",
    "\n",
    "        \n",
    "        sampled_word = tokenizer.token_to_word(token_int)\n",
    "\n",
    "        \n",
    "        output_text += \" \" + sampled_word\n",
    "\n",
    "        \n",
    "        count_tokens += 1\n",
    "\n",
    "   \n",
    "    output_tokens = decoder_input_data[0]\n",
    "\n",
    "    \n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(\"/scratch/shima/data/test2017/000000581763.jpg\", size=img_size)\n",
    "image.shape\n",
    "image_batch = np.expand_dims(image, axis=0)\n",
    "image_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img2 = load_image(\"/scratch/shima/data/val2017/000000432898.jpg\")\n",
    "plt.imshow(img2)\n",
    "plt.show()\n",
    "\n",
    "generate_caption(\"/scratch/shima/data/val2017/000000432898.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption_coco(idx, train=True):\n",
    "    \n",
    "    \n",
    "    if train:\n",
    "        \n",
    "        data_dir = coco.train_dir\n",
    "        filename = filenames_train[idx]\n",
    "        captions = captions_train[idx]\n",
    "    else:\n",
    "        \n",
    "        data_dir = coco.val_dir\n",
    "        filename = filenames_test[idx]\n",
    "        captions = captions_test[idx]\n",
    "\n",
    "    \n",
    "    path = os.path.join(data_dir, filename)\n",
    "\n",
    "    \n",
    "    output_text=generate_caption(image_path=path)\n",
    "  \n",
    "\n",
    "   \n",
    "        \n",
    "    return output_text,captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=102, train=False)\n",
    "generate_caption_coco(idx=102, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=5, train=False)\n",
    "generate_caption_coco(idx=5, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=896, train=False)\n",
    "generate_caption_coco(idx=896, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=53, train=False)\n",
    "generate_caption_coco(idx=53, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=200, train=False)\n",
    "generate_caption_coco(idx=200, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=22, train=False)\n",
    "generate_caption_coco(idx=22, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=436, train=False)\n",
    "generate_caption_coco(idx=436, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=83,train=False)\n",
    "generate_caption_coco(idx=83, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=573, train=False)\n",
    "generate_caption_coco(idx=573, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=48, train=False)\n",
    "generate_caption_coco(idx=48, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=27, train=False)\n",
    "generate_caption_coco(idx=27, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=1368, train=False)\n",
    "generate_caption_coco(idx=1368, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=1630, train=False)\n",
    "generate_caption_coco(idx=1630, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=4520, train=False)\n",
    "generate_caption_coco(idx=4520, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=414, train=False)\n",
    "generate_caption_coco(idx=414, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=794, train=False)\n",
    "generate_caption_coco(idx=794, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=3045, train=False)\n",
    "generate_caption_coco(idx=3045, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=630, train=False)\n",
    "generate_caption_coco(idx=630, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=2445, train=False)\n",
    "generate_caption_coco(idx=2445, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=3394, train=False)\n",
    "generate_caption_coco(idx=3394, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=1178, train=False)\n",
    "generate_caption_coco(idx=1178, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=145, train=False)\n",
    "generate_caption_coco(idx=145, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=4462, train=False)\n",
    "generate_caption_coco(idx=4462, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=3292, train=False)\n",
    "generate_caption_coco(idx=3292, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=2921, train=False)\n",
    "generate_caption_coco(idx=2921, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=190, train=False)\n",
    "generate_caption_coco(idx=190, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=703, train=False)\n",
    "generate_caption_coco(idx=703, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=8, train=False)\n",
    "generate_caption_coco(idx=8, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=1778, train=False)\n",
    "generate_caption_coco(idx=1778, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=606, train=False)\n",
    "generate_caption_coco(idx=606, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=983, train=False)\n",
    "generate_caption_coco(idx=983, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=744, train=False)\n",
    "generate_caption_coco(idx=744, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=515, train=False)\n",
    "generate_caption_coco(idx=515, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(idx=362, train=False)\n",
    "generate_caption_coco(idx=362, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[Predicted_caption,True_captions]=generate_caption_coco(idx=103, train=False)\n",
    "print(True_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Predicted_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "for idxx in range(len(filenames_val)):\n",
    "    [Predicted_caption,True_captions]=generate_caption_coco(idx=idxx, train=False)\n",
    "    candidate=Predicted_caption.split()\n",
    "    reference=[]\n",
    "    for caption in True_captions:\n",
    "        reference.append(caption.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_lcs(string, sub):\n",
    "  \n",
    "    if(len(string)< len(sub)):\n",
    "        sub, string = string, sub\n",
    "\n",
    "    lengths = [[0 for i in range(0,len(sub)+1)] for j in range(0,len(string)+1)]\n",
    "\n",
    "    for j in range(1,len(sub)+1):\n",
    "        for i in range(1,len(string)+1):\n",
    "            if(string[i-1] == sub[j-1]):\n",
    "                lengths[i][j] = lengths[i-1][j-1] + 1\n",
    "            else:\n",
    "                lengths[i][j] = max(lengths[i-1][j] , lengths[i][j-1])\n",
    "\n",
    "    return lengths[len(string)][len(sub)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def calc_score(candidate, refs):\n",
    "        \n",
    "        beta=1.2\n",
    "\n",
    "        prec = []\n",
    "        rec = []\n",
    "\n",
    "        \n",
    "        token_c = candidate.split(\" \")\n",
    "        for reference in refs:\n",
    "            \n",
    "            token_r = reference.split(\" \")\n",
    "            \n",
    "            lcs = my_lcs(token_r, token_c)\n",
    "            prec.append(lcs/float(len(token_c)))\n",
    "            rec.append(lcs/float(len(token_r)))\n",
    "\n",
    "        prec_max = max(prec)\n",
    "        rec_max = max(rec)\n",
    "\n",
    "        if(prec_max!=0 and rec_max !=0):\n",
    "            score = ((1 + beta**2)*prec_max*rec_max)/float(rec_max + beta**2*prec_max)\n",
    "        else:\n",
    "            score = 0.0\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from prettytable import PrettyTable\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "nltk.download('wordnet')\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "\n",
    "dat_dtype = {\n",
    "        'names' : ('idx', 'BLEU_1','BLEU_2','BLEU_3','BLEU_4','ROUGE','METEOR'),\n",
    "        'formats' : ('i', 'f','f','f','f','f','f')}\n",
    "dat = np.zeros(len(filenames_val), dat_dtype)\n",
    "\n",
    "x = PrettyTable(dat.dtype.names)\n",
    "for idxx in range(len(filenames_val)):\n",
    "\n",
    "    candidate=[]\n",
    "    reference=[]\n",
    "    [Predicted_caption,True_captions]=generate_caption_coco(idx=idxx, train=False)\n",
    "    candidate=Predicted_caption.split()\n",
    "    for caption in True_captions:\n",
    "        reference.append(caption.split())\n",
    "    dat['idx'][idxx] = idxx\n",
    "    dat['BLEU_1'][idxx] = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=chencherry.method4)\n",
    "    dat['BLEU_2'][idxx] = sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0), smoothing_function=chencherry.method4)\n",
    "    dat['BLEU_3'][idxx] = sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0), smoothing_function=chencherry.method4)\n",
    "    dat['BLEU_4'][idxx] = sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=chencherry.method4)    \n",
    "    dat['ROUGE'][idxx] = calc_score(Predicted_caption, True_captions)\n",
    "    dat['METEOR'][idxx] = round(meteor_score(True_captions,Predicted_caption),4)\n",
    "    \n",
    "np.save('results',dat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in dat:\n",
    "    x.add_row(row)\n",
    "\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "dat2_dtype = {\n",
    "        'names' : ('BLEU_1','BLEU_2','BLEU_3','BLEU_4','ROUGE','METEOR'),\n",
    "        'formats' : ('f','f','f','f','f','f')}\n",
    "dat2 = np.zeros(1, dat2_dtype)\n",
    "x2 = PrettyTable(dat2.dtype.names)\n",
    "\n",
    "dat2['BLEU_1']=np.mean(dat['BLEU_1'])\n",
    "dat2['BLEU_2']=np.mean(dat['BLEU_2'])\n",
    "dat2['BLEU_3']=np.mean(dat['BLEU_3'])\n",
    "dat2['BLEU_4']=np.mean(dat['BLEU_4'])\n",
    "# dat2['ROUGE']=np.mean(dat['ROUGE'])\n",
    "# dat2['METEOR']=np.mean(dat['METEOR'])\n",
    "\n",
    "# for row in dat2:\n",
    "#     x2.add_row(row)\n",
    "# print(x2)\n",
    "# # print(dat2)\n",
    "# np.save('dat_VGG',dat2)\n",
    "# data = np.load('dat_VGG.npy')\n",
    "# # print the array\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(dat['BLEU_3'][350:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=np.load('results1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "dat2_dtype = {\n",
    "        'names' : ('BLEU_1','BLEU_2','BLEU_3','BLEU_4','ROUGE','METEOR'),\n",
    "        'formats' : ('f','f','f','f','f','f')}\n",
    "dat2 = np.ones(3, dat2_dtype)\n",
    "x2 = PrettyTable(dat2.dtype.names)\n",
    "\n",
    "dat2['BLEU_1'][0]=np.max(dat['BLEU_1'])\n",
    "dat2['BLEU_2'][0]=np.max(dat['BLEU_2'])\n",
    "dat2['BLEU_3'][0]=np.max(dat['BLEU_3'])\n",
    "dat2['BLEU_4'][0]=np.max(dat['BLEU_4'])\n",
    "dat2['ROUGE'][0]=np.max(dat['ROUGE'])\n",
    "dat2['METEOR'][0]=np.max(dat['METEOR'])\n",
    "dat2['BLEU_1'][1]=np.mean(dat['BLEU_1'])\n",
    "dat2['BLEU_2'][1]=np.mean(dat['BLEU_2'])\n",
    "dat2['BLEU_3'][1]=np.mean(dat['BLEU_3'])\n",
    "dat2['BLEU_4'][1]=np.mean(dat['BLEU_4'])\n",
    "dat2['ROUGE'][1]=np.mean(dat['ROUGE'])\n",
    "dat2['METEOR'][1]=np.mean(dat['METEOR'])\n",
    "\n",
    "dat2['BLEU_1'][2]=np.mean(dat2['BLEU_1'])\n",
    "dat2['BLEU_2'][2]=np.mean(dat2['BLEU_2'])\n",
    "dat2['BLEU_3'][2]=np.mean(dat2['BLEU_3'])\n",
    "dat2['BLEU_4'][2]=np.mean(dat2['BLEU_4'])\n",
    "dat2['ROUGE'][2]=np.mean(dat2['ROUGE'])\n",
    "dat2['METEOR'][2]=np.mean(dat2['METEOR'])\n",
    "for row in dat2:\n",
    "    x2.add_row(row)\n",
    "print(x2)\n",
    "\n",
    "np.save('dat_VGG',dat2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(dat2['BLEU_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load('dat_VGG.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate=['a',\n",
    " 'plane',\n",
    " 'flying',\n",
    " 'in',\n",
    " 'the',\n",
    " 'sky',\n",
    " 'with',\n",
    " 'a',\n",
    " 'lot',\n",
    " 'of',\n",
    " 'smoke',\n",
    " 'eeee']\n",
    "reference=[['A', 'big', 'airplane', 'flying', 'in', 'the', 'big', 'blue', 'sky'],\n",
    " ['Large,', 'two', 'decked,', 'four', 'engined', 'airliner', 'in', 'flight.'],\n",
    " ['An', 'AirFrance', 'jet', 'airplane', 'flying', 'in', 'the', 'sky'],\n",
    " ['A', 'big', 'plane', 'with', 'AirFrance', 'on', 'the', 'side', 'of', 'it.'],\n",
    " ['An', 'Air', 'France', 'air', 'plane', 'in', 'mid', 'flight.']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference=[]\n",
    "for caption in True_captions:\n",
    "    reference.append(caption.split())\n",
    "reference\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE Bleu-1,2,3,4 Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "# score=sentence_bleu(reference,candidate)\n",
    "chencherry = SmoothingFunction()\n",
    "print('Cumulative bleu-1: %f' % sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=chencherry.method4))\n",
    "print('Cumulative bleu-2: %f' % sentence_bleu(reference, candidate, weights=(0.5, 0.5, 0, 0), smoothing_function=chencherry.method4))\n",
    "print('Cumulative bleu=3: %f' % sentence_bleu(reference, candidate, weights=(0.33, 0.33, 0.33, 0), smoothing_function=chencherry.method4))\n",
    "print('Cumulative bleu-4: %f' % sentence_bleu(reference, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=chencherry.method4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_captions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "True_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.meteor_score import meteor_score\n",
    "round(meteor_score(True_captions,Predicted_caption),4)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
